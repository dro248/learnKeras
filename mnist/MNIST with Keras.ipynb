{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning MNIST dataset with Keras\n",
    "\n",
    "Required Packages:\n",
    "* SciPy\n",
    "* NumPy\n",
    "* Matplotlib\n",
    "* Tensorflow or Theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# For reproducibility, use a static seed\n",
    "np.random.seed(123)\n",
    "\n",
    "# Keras model module\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Keras core layers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "# Keras CNN layers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Utilities\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image data from MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Load pre-shuffled MNIST data into training and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the first sample of X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f62586f1fd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess input data for Keras\n",
    "\n",
    "Our image data is of the form:\n",
    "> (n, width, height) \n",
    "> _where **n** is the number of images_.\n",
    "\n",
    "Target Form for our data:\n",
    "> We need our data to include **image depth** such that our data is of the form\n",
    "> (n, **depth**, width, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "# (60000, 28, 28)\n",
    "# - 60000 : images\n",
    "# -    28 : width  (px)\n",
    "# -    28 : height (px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of a single image\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pixel_value @ imgSet[img][row][col]\n",
    "X_train[0][10][12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Include image depth (where R,G,B = 3 deep)\n",
    "- MNIST images have a DEPTH of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input data\n",
    "DEPTH = 1\n",
    "# X_train = X_train.reshape(X_train.shape[0], DEPTH, 28, 28)\n",
    "# X_test = X_test.reshape(X_test.shape[0], DEPTH, 28, 28)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, DEPTH)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, DEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize pixel values\n",
    "\n",
    "Current Form:\n",
    "- int value (0 to 255)\n",
    "\n",
    "Target Form:\n",
    "- float value (0.0 to 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data type and normalize valuesPython\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess class labels for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "\n",
    "# (60000,)\n",
    "# 1-dimensional dataset ==> 10-dimensional dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Values of y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_values = set()\n",
    "[y_train_values.add(x) for x in y_train]\n",
    "\n",
    "# Show the set of values in y_train\n",
    "y_train_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split the values into their own columns\n",
    "\n",
    "Current Form:\n",
    "- y_train is a 1-dimensional array of values ranging from 0 to 9\n",
    "    - ( 0, 2, 9, 5, 1, ...)\n",
    "\n",
    "Target Form:\n",
    "- reshape y_train into a 10-dimensional array of classes where:\n",
    "    - each column corresponds to the class\n",
    "    - value at each column is 1 (True) or 0 (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# Reshape y_train so that it has 10 different classes\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# create Y_train\n",
    "Y_train =  np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(Y_train.shape)\n",
    "\n",
    "# (60000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In old form\n",
    "y_train[0]\n",
    "\n",
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In target (categorical) form\n",
    "Y_train[0]\n",
    "\n",
    "# array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Sequential model \n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: Kernel size & Sample (image) size\n",
    "\n",
    "The input shape parameter should be the shape of **1 sample**.\n",
    "In our case, since the image is 28 x 28, then the kernel will have the same shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv2D\n",
    "usage:\n",
    "> keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN input layer\n",
    "# Conv2D(numConvFiltersToUse, (numRowsInConvFilter, numColumnsInConvFilter))\n",
    "model.add(Conv2D(32, (3,3), input_shape=(28,28, 1), activation='relu'))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MaxPooling2D\n",
    "A way to reduce the number of parameters in our model by sliding a 2x2 across the previous layer and taking the max of the 4 values in the 2x2 filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DropOut\n",
    "A method for regularizing our model in order to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten\n",
    "It's important to note that the weights from the Convolution layers must be flattened (made 1-dimensional again) before we can pass them to the fully connected Dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense\n",
    "For Dense layers, the first parameter is the output size of the layer. Keras automatically handles the connections between layers (Dense = fully-connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model\n",
    "\n",
    "Compile the model so that we train it. When we compile the model, we declare things such as the **loss function**, the **optimizer** (SGD, adam, ...), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "To fit the model, all we have to do is declare the batch size and number of epochs to train for, then pass in our **training** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 306s - loss: 0.1112 - acc: 0.9677   \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 302s - loss: 0.0807 - acc: 0.9776   \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 302s - loss: 0.0707 - acc: 0.9803   \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 302s - loss: 0.0646 - acc: 0.9816   \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 302s - loss: 0.0636 - acc: 0.9823   \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 302s - loss: 0.0631 - acc: 0.9827   \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 303s - loss: 0.0649 - acc: 0.9824   \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 303s - loss: 0.0654 - acc: 0.9826   \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 303s - loss: 0.0656 - acc: 0.9823   \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 303s - loss: 0.0664 - acc: 0.9824   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f625c1763c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "          Y_train, \n",
    "          batch_size=32,\n",
    "          epochs=10, \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
